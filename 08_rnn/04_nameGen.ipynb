{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V33D9Ax7Xt_j"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.read_csv('data/name_gender_filtered.csv')\n",
        "unique_chars = set()\n",
        "\n",
        "for name in df['Name']:\n",
        "    unique_chars.update(name)\n",
        "    \n",
        "sorted_chars = sorted(list(unique_chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zdT1nqeXxHb",
        "outputId": "c1e79434-1d66-4d8e-eadb-930141a41458"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: '<S>', 27: '<E>'}\n"
          ]
        }
      ],
      "source": [
        "sorted_chars = sorted(set(''.join(sorted_chars)))\n",
        "stoi = {s:i for i,s in enumerate(sorted_chars)}\n",
        "stoi['<S>'] = len(stoi)\n",
        "stoi['<E>'] = len(stoi)\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(itos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU9DMZl7X0Fp",
        "outputId": "e902b35e-6b56-40a5-ced8-915c7499a27a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def name_to_one_hot(name):\n",
        "    # Add start and end tokens to the name\n",
        "    tokenized_name = ['<S>'] + list(name) + ['<E>']\n",
        "    int_tensor = torch.tensor([stoi[char] for char in tokenized_name])\n",
        "    one_hot_encoded = F.one_hot(int_tensor, num_classes=len(stoi)).float()\n",
        "    return one_hot_encoded\n",
        "\n",
        "\n",
        "print(name_to_one_hot(\"leo\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8GyYBxxMX3Pu"
      },
      "outputs": [],
      "source": [
        "from myRNN import *\n",
        "\n",
        "n_letters = len(stoi)\n",
        "n_hidden = 32\n",
        "rnn_model = MyRNN(n_letters, n_hidden, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled index: 0\n",
            "Sampled index: 0\n",
            "Sampled index: 2\n",
            "Sampled index: 0\n",
            "Sampled index: 0\n",
            "Sampled index: 1\n",
            "Sampled index: 0\n",
            "Sampled index: 0\n",
            "Sampled index: 0\n",
            "Sampled index: 0\n"
          ]
        }
      ],
      "source": [
        "prob = torch.tensor([0.7, 0.2, 0.1])\n",
        "\n",
        "print(f\"Sampled index: {torch.multinomial(prob, 1).item()}\")\n",
        "print(f\"Sampled index: {torch.multinomial(prob, 1).item()}\")\n",
        "print(f\"Sampled index: {torch.multinomial(prob, 1).item()}\")\n",
        "print(f\"Sampled index: {torch.multinomial(prob, 1).item()}\")\n",
        "print(f\"Sampled index: {torch.multinomial(prob, 1).item()}\")\n",
        "print(f\"Sampled index: {torch.multinomial(prob, 1).item()}\")\n",
        "print(f\"Sampled index: {torch.multinomial(prob, 1).item()}\")\n",
        "print(f\"Sampled index: {torch.multinomial(prob, 1).item()}\")\n",
        "print(f\"Sampled index: {torch.multinomial(prob, 1).item()}\")\n",
        "print(f\"Sampled index: {torch.multinomial(prob, 1).item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_-hMA7FX4jQ",
        "outputId": "8188d89c-107d-4b11-c839-33b8af5485fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "qjniyshieufurggrnre<S>\n"
          ]
        }
      ],
      "source": [
        "@torch.no_grad()\n",
        "def generate_name():\n",
        "    rnn_model.eval()\n",
        "    start_token_idx = torch.tensor(stoi['<S>'])\n",
        "    one_hot_encoded = F.one_hot(start_token_idx, num_classes=len(stoi)).float()\n",
        "    hidden = rnn_model.get_hidden()\n",
        "    char_list = []\n",
        "    for i in range(20):\n",
        "        out_score, hidden = rnn_model(one_hot_encoded[None,:],hidden)\n",
        "        score_probability = F.softmax(out_score[0], dim=-1)\n",
        "        out_idx = torch.multinomial(score_probability, 1).item()\n",
        "        if out_idx == stoi['<E>']:\n",
        "            break\n",
        "        char_list.append(itos[out_idx])\n",
        "        one_hot_encoded = F.one_hot(torch.tensor(out_idx), num_classes=len(stoi)).float()\n",
        "    print(''.join(char_list))\n",
        "\n",
        "\n",
        "generate_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZw6zHxRYA05"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(rnn_model.parameters(), lr=0.0001)\n",
        "\n",
        "for epoch_idx in range(100):\n",
        "    shuffled_df = df.sample(frac=1).reset_index(drop=True)\n",
        "    crnt_loss = 0.\n",
        "    rnn_model.train()\n",
        "    for index, row in shuffled_df.iterrows():\n",
        "\n",
        "        name_one_hot = name_to_one_hot(row['Name'])\n",
        "        hidden = rnn_model.get_hidden()\n",
        "        rnn_model.zero_grad()\n",
        "\n",
        "        losses = []\n",
        "        for char_idx in range(len(name_one_hot)-1):\n",
        "            input_tensor = name_one_hot[char_idx]\n",
        "            target_char = name_one_hot[char_idx+1]\n",
        "            target_class = torch.argmax(target_char, -1)\n",
        "            out_score, hidden = rnn_model(input_tensor[None,:],hidden)\n",
        "            losses.append(loss_fn(out_score[0], target_class))\n",
        "        loss = sum(losses)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        crnt_loss += loss.item()\n",
        "\n",
        "    generate_name()\n",
        "    average_loss = crnt_loss / len(df)\n",
        "\n",
        "    print(f'Iter idx {epoch_idx}, Loss: {average_loss:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imOpXEMxYC-q",
        "outputId": "28ccca00-02b9-4080-e8d8-9b07c6cc616a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ceairi\n",
            "lewnor\n",
            "valgwin\n",
            "shala\n",
            "ezmera\n",
            "raffamau\n",
            "kia\n",
            "jenavieve\n",
            "carlette\n",
            "sheily\n"
          ]
        }
      ],
      "source": [
        "generate_name()\n",
        "generate_name()\n",
        "generate_name()\n",
        "generate_name()\n",
        "generate_name()\n",
        "generate_name()\n",
        "generate_name()\n",
        "generate_name()\n",
        "generate_name()\n",
        "generate_name()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
