{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoCodeProgram/deepLearning/blob/main/rnn/nameGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAfockbHW2Ci",
        "outputId": "7883fa48-9eb8-4e42-c2cc-b8f1db049f6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deepLearning'...\n",
            "remote: Enumerating objects: 230, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 230 (delta 30), reused 0 (delta 0), pack-reused 139\u001b[K\n",
            "Receiving objects: 100% (230/230), 12.24 MiB | 17.10 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NoCodeProgram/deepLearning.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "df = pd.read_csv('./deepLearning/rnn/name_gender_filtered.csv')\n",
        "unique_chars = set()\n",
        "\n",
        "for name in df['Name']:\n",
        "    unique_chars.update(name)\n",
        "sorted_chars = sorted(list(unique_chars))\n"
      ],
      "metadata": {
        "id": "V33D9Ax7Xt_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_chars = sorted(set(''.join(sorted_chars)))\n",
        "stoi = {s:i for i,s in enumerate(sorted_chars)}\n",
        "stoi['<S>'] = len(stoi)\n",
        "stoi['<E>'] = len(stoi)\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zdT1nqeXxHb",
        "outputId": "c1e79434-1d66-4d8e-eadb-930141a41458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: '<S>', 27: '<E>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def name_to_one_hot(name):\n",
        "    # Add start and end tokens to the name\n",
        "    tokenized_name = ['<S>'] + list(name) + ['<E>']\n",
        "    int_tensor = torch.tensor([stoi[char] for char in tokenized_name])\n",
        "    one_hot_encoded = F.one_hot(int_tensor, num_classes=len(stoi)).float()\n",
        "    return one_hot_encoded\n",
        "\n",
        "\n",
        "print(name_to_one_hot(\"nocope\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU9DMZl7X0Fp",
        "outputId": "e902b35e-6b56-40a5-ced8-915c7499a27a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "n_letters = len(stoi)\n",
        "\n",
        "\n",
        "class MyRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = torch.tanh(self.i2h(combined))\n",
        "        output = self.h2o(hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def get_hidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "n_hidden = 1024\n",
        "rnn_model = MyRNN(n_letters, n_hidden, n_letters)"
      ],
      "metadata": {
        "id": "8GyYBxxMX3Pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def generate_name():\n",
        "    rnn_model.eval()\n",
        "    start_token_idx = torch.tensor(stoi['<S>'])\n",
        "    one_hot_encoded = F.one_hot(start_token_idx, num_classes=len(stoi)).float()\n",
        "    hidden = rnn_model.get_hidden()\n",
        "    char_list = []\n",
        "    for i in range(20):\n",
        "        out_score, hidden = rnn_model(one_hot_encoded[None,:],hidden)\n",
        "        score_probability = F.softmax(out_score[0], dim=-1)\n",
        "        out_idx = torch.multinomial(score_probability, 1).item()\n",
        "        if out_idx == stoi['<E>']:\n",
        "            break\n",
        "        char_list.append(itos[out_idx])\n",
        "        one_hot_encoded = F.one_hot(torch.tensor(out_idx), num_classes=len(stoi)).float()\n",
        "    print(''.join(char_list))\n",
        "\n",
        "\n",
        "generate_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_-hMA7FX4jQ",
        "outputId": "8188d89c-107d-4b11-c839-33b8af5485fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "qjniyshieufurggrnre<S>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.optim import Adam\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(rnn_model.parameters(), lr=0.0001)\n",
        "\n",
        "for epoch_idx in range(100):\n",
        "    shuffled_df = df.sample(frac=1).reset_index(drop=True)\n",
        "    crnt_loss = 0.\n",
        "    rnn_model.train()\n",
        "    for index, row in shuffled_df.iterrows():\n",
        "\n",
        "        name_one_hot = name_to_one_hot(row['Name'])\n",
        "        hidden = rnn_model.get_hidden()\n",
        "        rnn_model.zero_grad()\n",
        "\n",
        "        losses = []\n",
        "        for char_idx in range(len(name_one_hot)-1):\n",
        "            input_tensor = name_one_hot[char_idx]\n",
        "            target_char = name_one_hot[char_idx+1]\n",
        "            target_class = torch.argmax(target_char, -1)\n",
        "            out_score, hidden = rnn_model(input_tensor[None,:],hidden)\n",
        "            losses.append(loss_fn(out_score[0], target_class))\n",
        "        loss = sum(losses)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        crnt_loss += loss.item()\n",
        "\n",
        "    generate_name()\n",
        "    average_loss = crnt_loss / len(df)\n",
        "\n",
        "    print(f'Iter idx {epoch_idx}, Loss: {average_loss:.4f}')\n"
      ],
      "metadata": {
        "id": "DZw6zHxRYA05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_name()\n",
        "generate_name()\n",
        "generate_name()\n",
        "generate_name()\n",
        "generate_name()\n",
        "generate_name()\n",
        "generate_name()\n",
        "generate_name()\n",
        "generate_name()\n",
        "generate_name()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imOpXEMxYC-q",
        "outputId": "28ccca00-02b9-4080-e8d8-9b07c6cc616a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ceairi\n",
            "lewnor\n",
            "valgwin\n",
            "shala\n",
            "ezmera\n",
            "raffamau\n",
            "kia\n",
            "jenavieve\n",
            "carlette\n",
            "sheily\n"
          ]
        }
      ]
    }
  ]
}