{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCxgdPcaK8c5NxWG5TOql0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoCodeProgram/deepLearning/blob/main/rnn/charRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCXS_7KW3AeG",
        "outputId": "a7418394-40a6-4656-c325-56fd8d9290de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deepLearning'...\n",
            "remote: Enumerating objects: 166, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 166 (delta 10), reused 0 (delta 0), pack-reused 139\u001b[K\n",
            "Receiving objects: 100% (166/166), 4.38 MiB | 11.41 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NoCodeProgram/deepLearning.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = './deepLearning/rnn/name_country.csv'"
      ],
      "metadata": {
        "id": "IG7wfYBO3jx7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "df = pd.read_csv(data_file)\n",
        "text_data = df['Name'].tolist()\n",
        "label_data = df['Country'].tolist()\n",
        "\n",
        "country_list = sorted(set(label_data))\n",
        "country_count = len(country_list)\n",
        "\n",
        "data_dict = {} #key-country, value - list of names\n",
        "for name, country in zip(text_data, label_data):\n",
        "    if country not in data_dict:\n",
        "        data_dict[country] = []\n",
        "    data_dict[country].append(name)\n",
        "\n",
        "# print(data_dict)"
      ],
      "metadata": {
        "id": "gL-NSzTg3a9I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_letters = \"abcdefghijklmnopqrstuvwxyz ,'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "def nameToTensor(name):\n",
        "    tensor = torch.zeros(len(name), n_letters)\n",
        "    for char_idx, char in enumerate(name):\n",
        "        letter_idx = all_letters.find(char)\n",
        "        assert letter_idx != -1, f\"char is {name}, {char}\"\n",
        "        tensor[char_idx][letter_idx] = 1\n",
        "    return tensor\n"
      ],
      "metadata": {
        "id": "R_0AmPCs3rIv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "#Try other arch\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden = torch.zeros(1, self.hidden_size)\n",
        "\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        combined = torch.cat((input, self.hidden), 1)\n",
        "        self.hidden = torch.tanh(self.i2h(combined))\n",
        "        output = self.i2o(combined)\n",
        "        return output\n",
        "\n",
        "    def init_hidden(self):\n",
        "        self.hidden = torch.zeros(1, self.hidden_size)\n",
        "\n",
        "\n",
        "n_hidden = 32\n",
        "rnn_model = RNN(n_letters, n_hidden, country_count)"
      ],
      "metadata": {
        "id": "AqY9SuiS3s97"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from torch.optim import Adam, SGD\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = Adam(rnn_model.parameters(), lr=0.0001)\n",
        "iter_count = 3000000\n",
        "crnt_loss = 0.\n",
        "correct_predictions = 0\n",
        "\n",
        "for iter_idx in range(iter_count):\n",
        "    rnn_model.train()\n",
        "    random_country = random.choice(list(data_dict.keys()))\n",
        "    random_name = random.choice(data_dict[random_country])\n",
        "\n",
        "    name_tensor = nameToTensor(random_name)\n",
        "    country_tensor = torch.tensor([country_list.index(random_country)], dtype=torch.long)\n",
        "    rnn_model.init_hidden()\n",
        "    rnn_model.zero_grad()\n",
        "\n",
        "    for char_idx in range(len(random_name)):\n",
        "        char_tensor = name_tensor[char_idx]\n",
        "        output = rnn_model(char_tensor[None,:])\n",
        "\n",
        "    loss = loss_fn(output, country_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    crnt_loss += loss.item()\n",
        "    predicted_index = torch.argmax(output, 1)\n",
        "    correct_predictions += (predicted_index == country_tensor).sum().item()\n",
        "\n",
        "    if iter_idx % 10000 == 0 and iter_idx != 0:\n",
        "        average_loss = crnt_loss / 10000\n",
        "        accuracy = 100 * correct_predictions / 10000\n",
        "        print(f'Iter idx {iter_idx}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
        "        crnt_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL1y1p543v5_",
        "outputId": "108853a4-8674-4f5e-ffde-a65bd49b4b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter idx 5000, Loss: 2.8493, Accuracy: 12.74%\n",
            "Iter idx 10000, Loss: 2.6855, Accuracy: 25.56%\n",
            "Iter idx 15000, Loss: 2.4757, Accuracy: 26.50%\n",
            "Iter idx 20000, Loss: 2.3423, Accuracy: 32.56%\n",
            "Iter idx 25000, Loss: 2.2325, Accuracy: 35.84%\n",
            "Iter idx 30000, Loss: 2.1403, Accuracy: 37.86%\n",
            "Iter idx 35000, Loss: 2.0694, Accuracy: 38.50%\n",
            "Iter idx 40000, Loss: 2.0094, Accuracy: 40.30%\n",
            "Iter idx 45000, Loss: 1.9383, Accuracy: 42.54%\n",
            "Iter idx 50000, Loss: 1.8923, Accuracy: 43.74%\n",
            "Iter idx 55000, Loss: 1.8705, Accuracy: 44.18%\n",
            "Iter idx 60000, Loss: 1.8038, Accuracy: 45.70%\n",
            "Iter idx 65000, Loss: 1.7718, Accuracy: 45.56%\n",
            "Iter idx 70000, Loss: 1.7530, Accuracy: 45.58%\n",
            "Iter idx 75000, Loss: 1.6834, Accuracy: 48.44%\n",
            "Iter idx 80000, Loss: 1.6826, Accuracy: 47.84%\n",
            "Iter idx 85000, Loss: 1.6501, Accuracy: 48.96%\n",
            "Iter idx 90000, Loss: 1.6232, Accuracy: 48.20%\n",
            "Iter idx 95000, Loss: 1.6086, Accuracy: 49.32%\n",
            "Iter idx 100000, Loss: 1.5948, Accuracy: 49.76%\n",
            "Iter idx 105000, Loss: 1.5772, Accuracy: 50.66%\n",
            "Iter idx 110000, Loss: 1.5600, Accuracy: 51.00%\n",
            "Iter idx 115000, Loss: 1.5653, Accuracy: 50.60%\n",
            "Iter idx 120000, Loss: 1.5393, Accuracy: 50.54%\n",
            "Iter idx 125000, Loss: 1.5302, Accuracy: 51.82%\n",
            "Iter idx 130000, Loss: 1.5196, Accuracy: 51.30%\n",
            "Iter idx 135000, Loss: 1.4922, Accuracy: 51.22%\n",
            "Iter idx 140000, Loss: 1.4824, Accuracy: 52.90%\n",
            "Iter idx 145000, Loss: 1.4736, Accuracy: 53.16%\n",
            "Iter idx 150000, Loss: 1.4310, Accuracy: 54.40%\n",
            "Iter idx 155000, Loss: 1.4682, Accuracy: 52.32%\n",
            "Iter idx 160000, Loss: 1.4157, Accuracy: 54.84%\n",
            "Iter idx 165000, Loss: 1.4419, Accuracy: 53.74%\n",
            "Iter idx 170000, Loss: 1.4381, Accuracy: 54.44%\n",
            "Iter idx 175000, Loss: 1.4036, Accuracy: 53.36%\n",
            "Iter idx 180000, Loss: 1.3922, Accuracy: 54.24%\n",
            "Iter idx 185000, Loss: 1.4093, Accuracy: 53.68%\n",
            "Iter idx 190000, Loss: 1.3971, Accuracy: 54.56%\n",
            "Iter idx 195000, Loss: 1.3638, Accuracy: 54.64%\n",
            "Iter idx 200000, Loss: 1.3876, Accuracy: 55.22%\n",
            "Iter idx 205000, Loss: 1.3607, Accuracy: 55.96%\n",
            "Iter idx 210000, Loss: 1.3474, Accuracy: 56.30%\n",
            "Iter idx 215000, Loss: 1.3551, Accuracy: 56.30%\n",
            "Iter idx 220000, Loss: 1.3217, Accuracy: 56.70%\n",
            "Iter idx 225000, Loss: 1.3482, Accuracy: 55.70%\n",
            "Iter idx 230000, Loss: 1.3510, Accuracy: 56.20%\n",
            "Iter idx 235000, Loss: 1.3000, Accuracy: 58.28%\n",
            "Iter idx 240000, Loss: 1.3329, Accuracy: 56.14%\n",
            "Iter idx 245000, Loss: 1.3108, Accuracy: 57.34%\n",
            "Iter idx 250000, Loss: 1.3032, Accuracy: 58.04%\n",
            "Iter idx 255000, Loss: 1.3081, Accuracy: 56.44%\n",
            "Iter idx 260000, Loss: 1.3059, Accuracy: 57.30%\n",
            "Iter idx 265000, Loss: 1.3091, Accuracy: 56.74%\n",
            "Iter idx 270000, Loss: 1.3047, Accuracy: 57.48%\n",
            "Iter idx 275000, Loss: 1.2683, Accuracy: 59.48%\n",
            "Iter idx 280000, Loss: 1.2817, Accuracy: 58.56%\n",
            "Iter idx 285000, Loss: 1.2890, Accuracy: 58.14%\n",
            "Iter idx 290000, Loss: 1.2539, Accuracy: 59.68%\n",
            "Iter idx 295000, Loss: 1.2571, Accuracy: 59.76%\n",
            "Iter idx 300000, Loss: 1.2415, Accuracy: 59.70%\n",
            "Iter idx 305000, Loss: 1.2529, Accuracy: 60.02%\n",
            "Iter idx 310000, Loss: 1.2693, Accuracy: 58.94%\n",
            "Iter idx 315000, Loss: 1.2488, Accuracy: 59.16%\n",
            "Iter idx 320000, Loss: 1.2281, Accuracy: 60.22%\n",
            "Iter idx 325000, Loss: 1.2326, Accuracy: 60.96%\n",
            "Iter idx 330000, Loss: 1.2272, Accuracy: 60.46%\n",
            "Iter idx 335000, Loss: 1.1956, Accuracy: 61.74%\n",
            "Iter idx 340000, Loss: 1.2250, Accuracy: 60.24%\n",
            "Iter idx 345000, Loss: 1.2107, Accuracy: 62.34%\n",
            "Iter idx 350000, Loss: 1.2054, Accuracy: 60.72%\n",
            "Iter idx 355000, Loss: 1.1675, Accuracy: 62.64%\n",
            "Iter idx 360000, Loss: 1.1862, Accuracy: 61.82%\n",
            "Iter idx 365000, Loss: 1.2105, Accuracy: 61.40%\n",
            "Iter idx 370000, Loss: 1.1759, Accuracy: 61.98%\n",
            "Iter idx 375000, Loss: 1.1726, Accuracy: 62.68%\n",
            "Iter idx 380000, Loss: 1.1739, Accuracy: 62.54%\n",
            "Iter idx 385000, Loss: 1.1819, Accuracy: 62.36%\n",
            "Iter idx 390000, Loss: 1.1648, Accuracy: 63.10%\n",
            "Iter idx 395000, Loss: 1.1631, Accuracy: 63.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_name = 'nocope'\n",
        "test_name_tensor = nameToTensor(test_name)\n",
        "\n",
        "rnn_model.eval()\n",
        "rnn_model.init_hidden()\n",
        "for char_idx in range(len(test_name)):\n",
        "    char_tensor = test_name_tensor[char_idx]\n",
        "    output = rnn_model(char_tensor[None,:])\n",
        "predicted_index = torch.argmax(output, 1).item()\n",
        "print(country_list[predicted_index])\n",
        ""
      ],
      "metadata": {
        "id": "cxkdJSDB6RnK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}