{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoCodeProgram/deepLearning/blob/main/rnn/countryClassificationRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGQwCinK923S",
        "outputId": "36a069eb-cea2-4678-a194-4d49e000da1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deepLearning'...\n",
            "remote: Enumerating objects: 226, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 226 (delta 27), reused 0 (delta 0), pack-reused 139\u001b[K\n",
            "Receiving objects: 100% (226/226), 12.24 MiB | 20.48 MiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NoCodeProgram/deepLearning.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('./deepLearning/rnn/name_country.csv')\n",
        "text_data = df['Name'].tolist()\n",
        "label_data = df['Country'].tolist()\n",
        "\n",
        "country_list = sorted(set(label_data))\n",
        "country_count = len(country_list)\n",
        "\n",
        "data_dict = {} #key-country, value - list of names\n",
        "for name, country in zip(text_data, label_data):\n",
        "    if country not in data_dict:\n",
        "        data_dict[country] = []\n",
        "    data_dict[country].append(name)\n"
      ],
      "metadata": {
        "id": "u3RxOruo-D5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_chars = set()\n",
        "\n",
        "for name in df['Name']:\n",
        "    unique_chars.update(name)\n",
        "unique_chars = sorted(list(unique_chars))\n",
        "all_letters = ''.join(unique_chars)\n",
        "print(all_letters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oR2mjyj-glu",
        "outputId": "32c5de4b-890b-46d7-cad7-e398538d2b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ',abcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "def nameToTensor(name):\n",
        "    tensor = torch.zeros(len(name), n_letters)\n",
        "    for char_idx, char in enumerate(name):\n",
        "        letter_idx = all_letters.find(char)\n",
        "        assert letter_idx != -1, f\"char is {name}, {char}\"\n",
        "        tensor[char_idx][letter_idx] = 1\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "5bYZbyML-Dy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "#Try other arch\n",
        "class MyRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = torch.tanh(self.i2h(combined))\n",
        "        output = self.h2o(hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def get_hidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "\n",
        "n_hidden = 32\n",
        "rnn_model = MyRNN(n_letters, n_hidden, country_count)"
      ],
      "metadata": {
        "id": "7hr4RdvS-SFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from torch.optim import Adam, SGD\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = Adam(rnn_model.parameters(), lr=0.001) #Adam 1.2647557258605\n",
        "iter_count = 100000\n",
        "crnt_loss = 0.\n",
        "correct_predictions = 0\n",
        "\n",
        "for iter_idx in range(iter_count):\n",
        "    rnn_model.train()\n",
        "    random_country = random.choice(list(data_dict.keys()))\n",
        "    random_name = random.choice(data_dict[random_country])\n",
        "\n",
        "    name_tensor = nameToTensor(random_name)\n",
        "    country_tensor = torch.tensor([country_list.index(random_country)], dtype=torch.long)\n",
        "    hidden = rnn_model.get_hidden()\n",
        "    rnn_model.zero_grad()\n",
        "\n",
        "    for char_idx in range(len(random_name)):\n",
        "        char_tensor = name_tensor[char_idx]\n",
        "        output, hidden = rnn_model(char_tensor[None,:],hidden)\n",
        "\n",
        "    loss = loss_fn(output, country_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    crnt_loss += loss.item()\n",
        "    predicted_index = torch.argmax(output, 1)\n",
        "    correct_predictions += (predicted_index == country_tensor).sum().item()\n",
        "\n",
        "    if iter_idx % 5000 == 0 and iter_idx != 0:\n",
        "        average_loss = crnt_loss / 5000\n",
        "        accuracy = 100 * correct_predictions / 5000\n",
        "        print(f'Iter idx {iter_idx}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
        "        crnt_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_aeLRHP-kK9",
        "outputId": "b6085838-3c61-4650-f7fc-526b8258426e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter idx 5000, Loss: 2.1843, Accuracy: 32.30%\n",
            "Iter idx 10000, Loss: 1.6822, Accuracy: 44.54%\n",
            "Iter idx 15000, Loss: 1.5392, Accuracy: 49.22%\n",
            "Iter idx 20000, Loss: 1.4653, Accuracy: 50.68%\n",
            "Iter idx 25000, Loss: 1.4045, Accuracy: 53.66%\n",
            "Iter idx 30000, Loss: 1.3747, Accuracy: 55.50%\n",
            "Iter idx 35000, Loss: 1.3133, Accuracy: 56.92%\n",
            "Iter idx 40000, Loss: 1.2724, Accuracy: 58.60%\n",
            "Iter idx 45000, Loss: 1.2223, Accuracy: 59.24%\n",
            "Iter idx 50000, Loss: 1.2224, Accuracy: 60.14%\n",
            "Iter idx 55000, Loss: 1.1717, Accuracy: 61.46%\n",
            "Iter idx 60000, Loss: 1.1636, Accuracy: 61.84%\n",
            "Iter idx 65000, Loss: 1.1677, Accuracy: 62.06%\n",
            "Iter idx 70000, Loss: 1.0940, Accuracy: 64.38%\n",
            "Iter idx 75000, Loss: 1.1083, Accuracy: 63.06%\n",
            "Iter idx 80000, Loss: 1.1129, Accuracy: 63.20%\n",
            "Iter idx 85000, Loss: 1.0822, Accuracy: 65.00%\n",
            "Iter idx 90000, Loss: 1.0693, Accuracy: 64.96%\n",
            "Iter idx 95000, Loss: 1.0172, Accuracy: 66.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_name = 'jinping'\n",
        "test_name_tensor = nameToTensor(test_name)\n",
        "\n",
        "rnn_model.eval()\n",
        "hiddne = rnn_model.get_hidden()\n",
        "for char_idx in range(len(test_name)):\n",
        "    char_tensor = test_name_tensor[char_idx]\n",
        "    output, hidden = rnn_model(char_tensor[None,:],hidden)\n",
        "predicted_index = torch.argmax(output, 1).item()\n",
        "print(country_list[predicted_index])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur0q4xXo-moa",
        "outputId": "8a590ae4-ea95-4daa-b1f2-191a5922d916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chinese\n"
          ]
        }
      ]
    }
  ]
}