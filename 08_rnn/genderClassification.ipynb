{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoCodeProgram/deepLearning/blob/main/rnn/genderClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wBywrrqBjXm",
        "outputId": "b6ca7c27-907f-4ce9-edbc-0974fe345666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deepLearning'...\n",
            "remote: Enumerating objects: 222, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "remote: Total 222 (delta 24), reused 0 (delta 0), pack-reused 139\u001b[K\n",
            "Receiving objects: 100% (222/222), 12.24 MiB | 20.57 MiB/s, done.\n",
            "Resolving deltas: 100% (60/60), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NoCodeProgram/deepLearning.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.read_csv('./deepLearning/rnn/name_gender_filtered.csv')\n",
        "unique_chars = set()\n",
        "\n",
        "for name in df['Name']:\n",
        "    unique_chars.update(name)\n",
        "unique_chars = sorted(list(unique_chars))\n",
        "unique_chars = ''.join(unique_chars)\n",
        "print(unique_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLHxxDm9BmMZ",
        "outputId": "2aaf0832-9d1a-42ad-ca87-a398e3c8c045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_letters = len(unique_chars)\n",
        "def nameToTensor(name):\n",
        "    tensor = torch.zeros(len(name), n_letters)\n",
        "    for char_idx, char in enumerate(name):\n",
        "        letter_idx = unique_chars.find(char)\n",
        "        assert letter_idx != -1, f\"char is {name}, {char}\"\n",
        "        tensor[char_idx][letter_idx] = 1\n",
        "    return tensor\n",
        "\n",
        "gen2num = {'F':0, 'M':1}\n",
        "num2gen = {0:'F', 1:'M'}"
      ],
      "metadata": {
        "id": "TVnJTlR5CGqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "#Try other arch\n",
        "class MyRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = torch.tanh(self.i2h(combined))\n",
        "        output = self.h2o(hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def get_hidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "\n",
        "n_hidden = 32\n",
        "rnn_model = MyRNN(n_letters, n_hidden, 2)"
      ],
      "metadata": {
        "id": "pepscXaFCbF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(rnn_model.parameters(), lr=0.0001)\n",
        "\n",
        "\n",
        "rnn_model.train()\n",
        "for epoch_idx in range(200):\n",
        "    shuffled_df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    total_loss = 0.\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for index, row in shuffled_df.iterrows():\n",
        "        input_tensor = nameToTensor(row['Name'])\n",
        "        target_tensor = torch.tensor([gen2num[row['Gender']]], dtype=torch.long)\n",
        "\n",
        "        hidden = rnn_model.get_hidden()\n",
        "\n",
        "        rnn_model.zero_grad()\n",
        "\n",
        "        for char_idx in range(input_tensor.size()[0]):\n",
        "            char_tensor = input_tensor[char_idx]\n",
        "            output, hidden = rnn_model(char_tensor[None,:], hidden)\n",
        "\n",
        "        loss = loss_fn(output, target_tensor)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        predicted_index = torch.argmax(output, 1)\n",
        "        correct_predictions += (predicted_index == target_tensor).sum().item()\n",
        "        total_predictions += 1\n",
        "\n",
        "    average_loss = total_loss / total_predictions\n",
        "    accuracy = 100 * correct_predictions / total_predictions\n",
        "    print(f'Epoch: {epoch_idx}, Loss: {average_loss:.4f}, Accuracy: {accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf9ax5NBDXTc",
        "outputId": "e44c21aa-00cd-4fe4-b934-9f7848770350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.4543, Accuracy: 77.69%\n",
            "Epoch: 1, Loss: 0.3882, Accuracy: 82.74%\n",
            "Epoch: 2, Loss: 0.3799, Accuracy: 83.35%\n",
            "Epoch: 3, Loss: 0.3756, Accuracy: 83.63%\n",
            "Epoch: 4, Loss: 0.3726, Accuracy: 83.50%\n",
            "Epoch: 5, Loss: 0.3707, Accuracy: 83.73%\n",
            "Epoch: 6, Loss: 0.3697, Accuracy: 83.88%\n",
            "Epoch: 7, Loss: 0.3685, Accuracy: 83.88%\n",
            "Epoch: 8, Loss: 0.3682, Accuracy: 83.86%\n",
            "Epoch: 9, Loss: 0.3675, Accuracy: 83.82%\n",
            "Epoch: 10, Loss: 0.3671, Accuracy: 84.04%\n",
            "Epoch: 11, Loss: 0.3670, Accuracy: 83.95%\n",
            "Epoch: 12, Loss: 0.3664, Accuracy: 84.06%\n",
            "Epoch: 13, Loss: 0.3661, Accuracy: 84.08%\n",
            "Epoch: 14, Loss: 0.3655, Accuracy: 84.04%\n",
            "Epoch: 15, Loss: 0.3652, Accuracy: 84.15%\n",
            "Epoch: 16, Loss: 0.3644, Accuracy: 84.30%\n",
            "Epoch: 17, Loss: 0.3637, Accuracy: 84.28%\n",
            "Epoch: 18, Loss: 0.3631, Accuracy: 84.28%\n",
            "Epoch: 19, Loss: 0.3629, Accuracy: 84.33%\n",
            "Epoch: 20, Loss: 0.3620, Accuracy: 84.31%\n",
            "Epoch: 21, Loss: 0.3610, Accuracy: 84.38%\n",
            "Epoch: 22, Loss: 0.3601, Accuracy: 84.40%\n",
            "Epoch: 23, Loss: 0.3592, Accuracy: 84.50%\n",
            "Epoch: 24, Loss: 0.3580, Accuracy: 84.36%\n",
            "Epoch: 25, Loss: 0.3570, Accuracy: 84.58%\n",
            "Epoch: 26, Loss: 0.3553, Accuracy: 84.68%\n",
            "Epoch: 27, Loss: 0.3543, Accuracy: 84.65%\n",
            "Epoch: 28, Loss: 0.3530, Accuracy: 84.87%\n",
            "Epoch: 29, Loss: 0.3514, Accuracy: 84.93%\n",
            "Epoch: 30, Loss: 0.3499, Accuracy: 85.05%\n",
            "Epoch: 31, Loss: 0.3479, Accuracy: 85.16%\n",
            "Epoch: 32, Loss: 0.3468, Accuracy: 85.04%\n",
            "Epoch: 33, Loss: 0.3446, Accuracy: 85.24%\n",
            "Epoch: 34, Loss: 0.3425, Accuracy: 85.35%\n",
            "Epoch: 35, Loss: 0.3409, Accuracy: 85.44%\n",
            "Epoch: 36, Loss: 0.3391, Accuracy: 85.42%\n",
            "Epoch: 37, Loss: 0.3363, Accuracy: 85.60%\n",
            "Epoch: 38, Loss: 0.3355, Accuracy: 85.67%\n",
            "Epoch: 39, Loss: 0.3333, Accuracy: 85.68%\n",
            "Epoch: 40, Loss: 0.3313, Accuracy: 85.97%\n",
            "Epoch: 41, Loss: 0.3294, Accuracy: 85.95%\n",
            "Epoch: 42, Loss: 0.3278, Accuracy: 86.08%\n",
            "Epoch: 43, Loss: 0.3256, Accuracy: 86.27%\n",
            "Epoch: 44, Loss: 0.3239, Accuracy: 86.32%\n",
            "Epoch: 45, Loss: 0.3219, Accuracy: 86.49%\n",
            "Epoch: 46, Loss: 0.3201, Accuracy: 86.46%\n",
            "Epoch: 47, Loss: 0.3178, Accuracy: 86.62%\n",
            "Epoch: 48, Loss: 0.3155, Accuracy: 86.77%\n",
            "Epoch: 49, Loss: 0.3141, Accuracy: 86.95%\n",
            "Epoch: 50, Loss: 0.3116, Accuracy: 87.06%\n",
            "Epoch: 51, Loss: 0.3103, Accuracy: 87.07%\n",
            "Epoch: 52, Loss: 0.3078, Accuracy: 87.28%\n",
            "Epoch: 53, Loss: 0.3056, Accuracy: 87.28%\n",
            "Epoch: 54, Loss: 0.3036, Accuracy: 87.43%\n",
            "Epoch: 55, Loss: 0.3018, Accuracy: 87.67%\n",
            "Epoch: 56, Loss: 0.2993, Accuracy: 87.55%\n",
            "Epoch: 57, Loss: 0.2975, Accuracy: 87.69%\n",
            "Epoch: 58, Loss: 0.2954, Accuracy: 87.79%\n",
            "Epoch: 59, Loss: 0.2932, Accuracy: 87.88%\n",
            "Epoch: 60, Loss: 0.2914, Accuracy: 88.17%\n",
            "Epoch: 61, Loss: 0.2903, Accuracy: 88.06%\n",
            "Epoch: 62, Loss: 0.2884, Accuracy: 88.36%\n",
            "Epoch: 63, Loss: 0.2861, Accuracy: 88.40%\n",
            "Epoch: 64, Loss: 0.2847, Accuracy: 88.55%\n",
            "Epoch: 65, Loss: 0.2832, Accuracy: 88.64%\n",
            "Epoch: 66, Loss: 0.2806, Accuracy: 88.76%\n",
            "Epoch: 67, Loss: 0.2800, Accuracy: 88.72%\n",
            "Epoch: 68, Loss: 0.2780, Accuracy: 88.77%\n",
            "Epoch: 69, Loss: 0.2765, Accuracy: 89.05%\n",
            "Epoch: 70, Loss: 0.2751, Accuracy: 88.83%\n",
            "Epoch: 71, Loss: 0.2743, Accuracy: 89.02%\n",
            "Epoch: 72, Loss: 0.2722, Accuracy: 89.25%\n",
            "Epoch: 73, Loss: 0.2715, Accuracy: 89.06%\n",
            "Epoch: 74, Loss: 0.2707, Accuracy: 89.06%\n",
            "Epoch: 75, Loss: 0.2690, Accuracy: 89.29%\n",
            "Epoch: 76, Loss: 0.2676, Accuracy: 89.33%\n",
            "Epoch: 77, Loss: 0.2671, Accuracy: 89.40%\n",
            "Epoch: 78, Loss: 0.2653, Accuracy: 89.39%\n",
            "Epoch: 79, Loss: 0.2642, Accuracy: 89.36%\n",
            "Epoch: 80, Loss: 0.2629, Accuracy: 89.53%\n",
            "Epoch: 81, Loss: 0.2620, Accuracy: 89.52%\n",
            "Epoch: 82, Loss: 0.2604, Accuracy: 89.58%\n",
            "Epoch: 83, Loss: 0.2593, Accuracy: 89.67%\n",
            "Epoch: 84, Loss: 0.2588, Accuracy: 89.68%\n",
            "Epoch: 85, Loss: 0.2569, Accuracy: 89.68%\n",
            "Epoch: 86, Loss: 0.2564, Accuracy: 89.56%\n",
            "Epoch: 87, Loss: 0.2558, Accuracy: 89.72%\n",
            "Epoch: 88, Loss: 0.2541, Accuracy: 89.74%\n",
            "Epoch: 89, Loss: 0.2535, Accuracy: 89.92%\n",
            "Epoch: 90, Loss: 0.2520, Accuracy: 90.04%\n",
            "Epoch: 91, Loss: 0.2512, Accuracy: 89.90%\n",
            "Epoch: 92, Loss: 0.2501, Accuracy: 90.05%\n",
            "Epoch: 93, Loss: 0.2496, Accuracy: 90.07%\n",
            "Epoch: 94, Loss: 0.2479, Accuracy: 89.96%\n",
            "Epoch: 95, Loss: 0.2467, Accuracy: 90.20%\n",
            "Epoch: 96, Loss: 0.2457, Accuracy: 90.23%\n",
            "Epoch: 97, Loss: 0.2446, Accuracy: 90.22%\n",
            "Epoch: 98, Loss: 0.2430, Accuracy: 90.33%\n",
            "Epoch: 99, Loss: 0.2421, Accuracy: 90.32%\n",
            "Epoch: 100, Loss: 0.2412, Accuracy: 90.26%\n",
            "Epoch: 101, Loss: 0.2404, Accuracy: 90.31%\n",
            "Epoch: 102, Loss: 0.2391, Accuracy: 90.48%\n",
            "Epoch: 103, Loss: 0.2383, Accuracy: 90.43%\n",
            "Epoch: 104, Loss: 0.2375, Accuracy: 90.46%\n",
            "Epoch: 105, Loss: 0.2365, Accuracy: 90.37%\n",
            "Epoch: 106, Loss: 0.2354, Accuracy: 90.50%\n",
            "Epoch: 107, Loss: 0.2336, Accuracy: 90.77%\n",
            "Epoch: 108, Loss: 0.2328, Accuracy: 90.64%\n",
            "Epoch: 109, Loss: 0.2323, Accuracy: 90.71%\n",
            "Epoch: 110, Loss: 0.2309, Accuracy: 90.74%\n",
            "Epoch: 111, Loss: 0.2301, Accuracy: 90.85%\n",
            "Epoch: 112, Loss: 0.2297, Accuracy: 90.63%\n",
            "Epoch: 113, Loss: 0.2282, Accuracy: 91.01%\n",
            "Epoch: 114, Loss: 0.2268, Accuracy: 90.86%\n",
            "Epoch: 115, Loss: 0.2261, Accuracy: 91.03%\n",
            "Epoch: 116, Loss: 0.2260, Accuracy: 90.99%\n",
            "Epoch: 117, Loss: 0.2243, Accuracy: 91.03%\n",
            "Epoch: 118, Loss: 0.2237, Accuracy: 91.15%\n",
            "Epoch: 119, Loss: 0.2228, Accuracy: 91.25%\n",
            "Epoch: 120, Loss: 0.2216, Accuracy: 91.20%\n",
            "Epoch: 121, Loss: 0.2203, Accuracy: 91.19%\n",
            "Epoch: 122, Loss: 0.2198, Accuracy: 91.33%\n",
            "Epoch: 123, Loss: 0.2185, Accuracy: 91.17%\n",
            "Epoch: 124, Loss: 0.2178, Accuracy: 91.24%\n",
            "Epoch: 125, Loss: 0.2168, Accuracy: 91.36%\n",
            "Epoch: 126, Loss: 0.2170, Accuracy: 91.37%\n",
            "Epoch: 127, Loss: 0.2153, Accuracy: 91.52%\n",
            "Epoch: 128, Loss: 0.2144, Accuracy: 91.54%\n",
            "Epoch: 129, Loss: 0.2130, Accuracy: 91.47%\n",
            "Epoch: 130, Loss: 0.2130, Accuracy: 91.56%\n",
            "Epoch: 131, Loss: 0.2115, Accuracy: 91.52%\n",
            "Epoch: 132, Loss: 0.2115, Accuracy: 91.66%\n",
            "Epoch: 133, Loss: 0.2106, Accuracy: 91.67%\n",
            "Epoch: 134, Loss: 0.2098, Accuracy: 91.86%\n",
            "Epoch: 135, Loss: 0.2087, Accuracy: 91.82%\n",
            "Epoch: 136, Loss: 0.2084, Accuracy: 91.72%\n",
            "Epoch: 137, Loss: 0.2066, Accuracy: 91.98%\n",
            "Epoch: 138, Loss: 0.2061, Accuracy: 91.85%\n",
            "Epoch: 139, Loss: 0.2049, Accuracy: 91.76%\n",
            "Epoch: 140, Loss: 0.2054, Accuracy: 91.94%\n",
            "Epoch: 141, Loss: 0.2045, Accuracy: 92.11%\n",
            "Epoch: 142, Loss: 0.2026, Accuracy: 92.10%\n",
            "Epoch: 143, Loss: 0.2027, Accuracy: 92.00%\n",
            "Epoch: 144, Loss: 0.2021, Accuracy: 91.92%\n",
            "Epoch: 145, Loss: 0.2012, Accuracy: 91.99%\n",
            "Epoch: 146, Loss: 0.2005, Accuracy: 92.09%\n",
            "Epoch: 147, Loss: 0.2000, Accuracy: 92.20%\n",
            "Epoch: 148, Loss: 0.1989, Accuracy: 92.25%\n",
            "Epoch: 149, Loss: 0.1983, Accuracy: 92.23%\n",
            "Epoch: 150, Loss: 0.1971, Accuracy: 92.17%\n",
            "Epoch: 151, Loss: 0.1970, Accuracy: 92.26%\n",
            "Epoch: 152, Loss: 0.1966, Accuracy: 92.31%\n",
            "Epoch: 153, Loss: 0.1959, Accuracy: 92.31%\n",
            "Epoch: 154, Loss: 0.1950, Accuracy: 92.36%\n",
            "Epoch: 155, Loss: 0.1943, Accuracy: 92.25%\n",
            "Epoch: 156, Loss: 0.1940, Accuracy: 92.38%\n",
            "Epoch: 157, Loss: 0.1922, Accuracy: 92.48%\n",
            "Epoch: 158, Loss: 0.1923, Accuracy: 92.48%\n",
            "Epoch: 159, Loss: 0.1911, Accuracy: 92.38%\n",
            "Epoch: 160, Loss: 0.1914, Accuracy: 92.38%\n",
            "Epoch: 161, Loss: 0.1908, Accuracy: 92.44%\n",
            "Epoch: 162, Loss: 0.1904, Accuracy: 92.50%\n",
            "Epoch: 163, Loss: 0.1893, Accuracy: 92.57%\n",
            "Epoch: 164, Loss: 0.1889, Accuracy: 92.61%\n",
            "Epoch: 165, Loss: 0.1884, Accuracy: 92.55%\n",
            "Epoch: 166, Loss: 0.1884, Accuracy: 92.60%\n",
            "Epoch: 167, Loss: 0.1862, Accuracy: 92.87%\n",
            "Epoch: 168, Loss: 0.1870, Accuracy: 92.54%\n",
            "Epoch: 169, Loss: 0.1854, Accuracy: 92.67%\n",
            "Epoch: 170, Loss: 0.1850, Accuracy: 92.64%\n",
            "Epoch: 171, Loss: 0.1844, Accuracy: 92.75%\n",
            "Epoch: 172, Loss: 0.1841, Accuracy: 92.73%\n",
            "Epoch: 173, Loss: 0.1839, Accuracy: 92.69%\n",
            "Epoch: 174, Loss: 0.1831, Accuracy: 92.87%\n",
            "Epoch: 175, Loss: 0.1825, Accuracy: 92.75%\n",
            "Epoch: 176, Loss: 0.1822, Accuracy: 92.87%\n",
            "Epoch: 177, Loss: 0.1813, Accuracy: 92.90%\n",
            "Epoch: 178, Loss: 0.1807, Accuracy: 92.77%\n",
            "Epoch: 179, Loss: 0.1802, Accuracy: 92.99%\n",
            "Epoch: 180, Loss: 0.1805, Accuracy: 92.92%\n",
            "Epoch: 181, Loss: 0.1790, Accuracy: 92.97%\n",
            "Epoch: 182, Loss: 0.1788, Accuracy: 92.94%\n",
            "Epoch: 183, Loss: 0.1780, Accuracy: 93.11%\n",
            "Epoch: 184, Loss: 0.1771, Accuracy: 93.08%\n",
            "Epoch: 185, Loss: 0.1769, Accuracy: 92.95%\n",
            "Epoch: 186, Loss: 0.1770, Accuracy: 92.98%\n",
            "Epoch: 187, Loss: 0.1768, Accuracy: 93.10%\n",
            "Epoch: 188, Loss: 0.1761, Accuracy: 93.08%\n",
            "Epoch: 189, Loss: 0.1754, Accuracy: 93.14%\n",
            "Epoch: 190, Loss: 0.1741, Accuracy: 93.16%\n",
            "Epoch: 191, Loss: 0.1750, Accuracy: 93.19%\n",
            "Epoch: 192, Loss: 0.1741, Accuracy: 93.13%\n",
            "Epoch: 193, Loss: 0.1741, Accuracy: 93.18%\n",
            "Epoch: 194, Loss: 0.1730, Accuracy: 93.37%\n",
            "Epoch: 195, Loss: 0.1728, Accuracy: 93.23%\n",
            "Epoch: 196, Loss: 0.1723, Accuracy: 93.17%\n",
            "Epoch: 197, Loss: 0.1723, Accuracy: 93.12%\n",
            "Epoch: 198, Loss: 0.1710, Accuracy: 93.29%\n",
            "Epoch: 199, Loss: 0.1714, Accuracy: 93.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_name = 'elsa'\n",
        "test_name_tensor = nameToTensor(test_name)\n",
        "\n",
        "rnn_model.eval()\n",
        "hiddne = rnn_model.get_hidden()\n",
        "for char_idx in range(len(test_name)):\n",
        "    char_tensor = test_name_tensor[char_idx]\n",
        "    output, hidden = rnn_model(char_tensor[None,:],hidden)\n",
        "predicted_index = torch.argmax(output, 1).item()\n",
        "print(num2gen[predicted_index])\n"
      ],
      "metadata": {
        "id": "LX0vMHVJOPaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "051b3ec7-63ca-41d9-8965-1cee9f898c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n"
          ]
        }
      ]
    }
  ]
}